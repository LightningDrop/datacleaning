{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 1  - Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset - Candy Hierarchy 2017\n",
    "https://www.scq.ubc.ca/so-much-candy-data-seriously/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define functions and variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_text_index(df, name):\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    df[name] = le.fit_transform(df[name])\n",
    "    return le.classes_\n",
    "\n",
    "unit_dict = np.load('dictionary.npy',allow_pickle='TRUE').item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in dataset as Pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/candyhierarchy2017.csv', encoding = \"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing of unnecessary rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop rows base on their index value.\n",
    "#To test this, drop index 0 first since that row do not have any record.\n",
    "df = df.drop(0)\n",
    "\n",
    "#Show and check if the row is deleted\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Begin dropping rows: upon observation, rows that have multiple missing data starts to miss input in the column  \"Q6 | Any full-sized candy bar,\" so this column is used as a \"filter\" to drop these rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset = ['Q6 | Any full-sized candy bar'])\n",
    "df.head()\n",
    "\n",
    "#create a new updated candyfile dataset\n",
    "df.to_csv('updated_candy_set_rows.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing of Unnecessary Columns\n",
    "---\n",
    "This is the removing of columns that are deemed as not needed for our finalized data, so as part of the preprocessing process we are removing said data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After storing the data to a file, by looking at the survey that was provided for the candy hierarchy, columns will be dropped because they do not serve a value.\n",
    "\n",
    "---\n",
    "\n",
    "The following colums were removed for these reasons:\n",
    "- > Internal ID: No value with our data\n",
    "- > Q1 : Not a candy question\n",
    "- > Q6 : Not a candy\n",
    "- > Q7, Q8, Q9: Comments serving no value\n",
    "- > Q10, Q11, Q13: Not a candy question\n",
    "- > Unamed: 113: Blank column with no value\n",
    "- > Click Coordinates (x, y): Not of significant value to candy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All columns from the data set that will be removed\n",
    "col_remove = [\"Internal ID\", \"Q1: GOING OUT?\", \n",
    "\"Q6 | Anonymous brown globs that come in black and orange wrappers\t(a.k.a. Mary Janes)\", \n",
    "\"Q6 | Any full-sized candy bar\", \"Q6 | Bonkers (the board game)\", \"Q6 | Box'o'Raisins\",\n",
    "\"Q6 | Broken glow stick\", \n",
    "\"Q6 | Candy that is clearly just the stuff given out for free at restaurants\", \n",
    "\"Q6 | Cash, or other forms of legal tender\", \"Q6 | Chardonnay\", \n",
    "\"Q6 | Chick-o-Sticks (we donÃ•t know what that is)\",\n",
    "\"Q6 | Creepy Religious comics/Chick Tracts\", \"Q6 | Dental paraphenalia\", \n",
    "\"Q6 | Generic Brand Acetaminophen\", \"Q6 | Glow sticks\", \"Q6 | Green Party M&M's\", \n",
    "\"Q6 | Gum from baseball cards\", \"Q6 | Independent M&M's\",\n",
    "\"Q6 | Gummy Bears straight up\", \"Q6 | Healthy Fruit\", \"Q6 | Hugs (actual physical hugs)\",\n",
    "\"Q6 | Jolly Rancher (bad flavor)\", \"Q6 | JoyJoy (Mit Iodine!)\", \"Q6 | Senior Mints\",\n",
    "\"Q6 | Kale smoothie\", \"Q6 | Abstained from M&M'ing.\", \"Q6 | Pencils\", \n",
    "\"Q6 | Mint Juleps\", \"Q6 | Spotted Dick\", \"Q6 | Minibags of chips\", \n",
    "\"Q6 | Real Housewives of Orange County Season 9 Blue-Ray\",\n",
    "\"Q6 | Sandwich-sized bags filled with BooBerry Crunch\",\n",
    "\"Q6 | Those odd marshmallow circus peanut things\", \n",
    "\"Q6 | Vials of pure high fructose corn syrup, for main-lining into your vein\", \n",
    "\"Q6 | Vicodin\", \"Q6 | White Bread\", \"Q6 | Whole Wheat anything\", \n",
    "\"Q7: JOY OTHER\", \"Q8: DESPAIR OTHER\", \"Q9: OTHER COMMENTS\", \"Q10: DRESS\", \n",
    "\"Unnamed: 113\", \"Q11: DAY\", \"Q12: MEDIA [Daily Dish]\", \"Q12: MEDIA [Science]\", \"Q12: MEDIA [ESPN]\", \n",
    "\"Q12: MEDIA [Yahoo]\", \"Click Coordinates (x, y)\"]\n",
    "\n",
    "# Files are dropped from the dataframe\n",
    "df = df.drop(columns = col_remove)\n",
    "\n",
    "# New dataframe is saved to relative file location and name\n",
    "df.to_csv('candydata_col_removed.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Columns in the data are now removed and stored to the variable in the final line of code above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset = ['Q6 | Any full-sized candy bar'])\n",
    "df.head()\n",
    "\n",
    "#create a new updated candyfile dataset\n",
    "df.to_csv('updated_candy_set_rows.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## After this process, rows are now sorted with the ones that have multiple data entry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning Age Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing rows where age is not an integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[pd.to_numeric(df['Q3: AGE'], errors='coerce').notnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3279e81a",
   "metadata": {},
   "source": [
    "# Normalizing Genders\n",
    " Normalizing and mapping to values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replacing NaN with \"I'd rather not say\" since it makes more sense, rather than just deleting..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Q2: GENDER'].fillna(value = \"I'd rather not say\", inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maps a value to each..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = {\"Male\": '0', 'Female': '1', \"I'd rather not say\" : '2', 'other' : '3' }\n",
    "df = df.replace({\"Q2: GENDER\": df2})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalizing Countries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalizing States, Cities, Provinces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert dictionary and target column to uppercase before mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unit_dict =  {k.upper(): v for k, v in unit_dict.items()}\n",
    "df['Q5: STATE, PROVINCE, COUNTY, ETC'] = df['Q5: STATE, PROVINCE, COUNTY, ETC'].str.upper()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Map values in column to their corresponding dictionary key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Q5: STATE, PROVINCE, COUNTY, ETC'] = df['Q5: STATE, PROVINCE, COUNTY, ETC'].map(unit_dict).fillna(df['Q5: STATE, PROVINCE, COUNTY, ETC'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display counts of unique values after mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Q5: STATE, PROVINCE, COUNTY, ETC'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Label encode each state or province after mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encode_text_index(df, 'Q5: STATE, PROVINCE, COUNTY, ETC')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalizing Candy Ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in df.columns:\n",
    "    df[index] = df[index].replace(['MEH', 'JOY', 'DESPAIR'], ['1', '2', '0'])\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replacing missing values options\n",
    "---\n",
    "### Replace with meh\n",
    "    > file[index] = file[index].fillna(1)\n",
    "- Decided upon this for candy sections because mean would not work for our categorical needs\n",
    "\n",
    "### Replace with new value\n",
    "    > file[index] = file[index].fillna(2)\n",
    "- Decided upon this for gender and location\n",
    "\n",
    "### Replace with mean\n",
    "    > To use/do mean, make sure that data is in int\n",
    "    > file[index] = file[index].fillna(file[index].mean())\n",
    "- Decided upon this for age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This for loop loops through every column in the data set\n",
    "for index in df.columns:\n",
    "    if index == 'Q2: GENDER':\n",
    "        # Gender fill in | Creating a third option of other/nan\n",
    "        df[index] = df[index].fillna(2)\n",
    "    elif index == 'Q3: AGE':\n",
    "        # Age fill in | Age must be normalized for this to work (no strings)\n",
    "        df[index] = df[index].fillna(df[index].mean())\n",
    "        pass\n",
    "    elif index == 'Q5: STATE, PROVINCE, COUNTY, ETC':\n",
    "        # Country & State/Province fill in | Creating a third option of other/nan\n",
    "        df[index] = df[index].fillna(2)  \n",
    "    else: # If it is in the candy column\n",
    "        df[index] = df[index].fillna(1)\n",
    "\n",
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0f90a3ab1965d6b9c6f93d33fe8507cc150802699b5d1025341132004af4d075"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
